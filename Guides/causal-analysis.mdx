---
title: 'Causal Analysis'
description: 'Bring the power of AI prediction into Impact measurement and validation methodologies'
---

<Note>
  Causal analysis uses AI to understand true impact by modeling counterfactuals and controlling for confounding variables.
</Note>

<AccordionGroup>
  <Accordion title="Counterfactual Modeling">
    * Baseline scenario simulation

    * Alternative fuel pathways

    * Seasonal variations

    * Economic factors
  </Accordion>

  <Accordion title="Confounding Variables">
    * Household size changes

    * Income fluctuations

    * Weather patterns

    * Market prices
  </Accordion>
</AccordionGroup>

```python
from emerging import CausalModel, Household

# Initialize causal model
model = CausalModel(
    treatment="clean_stove_adoption",
    outcome="emissions",
    confounders=[
        "household_size",
        "income_level",
        "seasonal_temp"
    ]
)

# Analyze household impact
household = Household.get("did:ixo:household/123")
impact = model.analyze(
    household=household,
    period_start="2024-01-01",
    period_end="2024-01-31",
    confidence_level=0.95
)

# Get causal effects
print(f"Average Treatment Effect: {impact.ate}")
print(f"Confidence Interval: {impact.confidence_interval}")
```

### Impact Attribution

```json
{
  "householdId": "did:ixo:household/123",
  "period": {
    "start": "2024-01-01",
    "end": "2024-01-31"
  },
  "analysis": {
    "baselineEmissions": 120,
    "actualEmissions": 45,
    "reductions": 75,
    "confidence": 0.95,
    "causalFactors": {
      "cleanStoveAdoption": 0.65,
      "seasonalEffect": 0.15,
      "incomeChange": 0.10,
      "unexplained": 0.10
    },
    "deviceContributions": [{
      "deviceId": "did:ixo:device/456",
      "reductionShare": 0.8,
      "evidence": {
        "usageHours": 120,
        "fuelSaved": 32,
        "causalStrength": 0.85
      }
    }],
    "confounders": {
      "householdSize": {
        "baseline": 4,
        "current": 4,
        "effect": "neutral"
      },
      "income": {
        "direction": "increased",
        "effect": "positive",
        "magnitude": 0.1
      }
    }
  }
}
```

### Verification Process

<CodeGroup>
  ```python Causal Verification
  from emerging import CausalOracle, Evidence

  # Initialize causal oracle
  oracle = CausalOracle(
      min_confidence=0.95,
      required_evidence=["telemetry", "surveys", "market_data"]
  )

  # Verify causal claims
  verification = oracle.verify_household(
      household_id="did:ixo:household/123",
      period_start="2024-01-01",
      period_end="2024-01-31",
      evidence={
          "telemetry": device_data,
          "surveys": survey_data,
          "market_data": market_prices
      }
  )

  # Generate verification report
  if verification.is_valid:
      report = verification.generate_report()
      print(f"Causal Strength: {report.causal_strength}")
      print(f"Confidence Level: {report.confidence}")
  ```

  ```javascript
  import { CausalOracle, Evidence } from '@emerging/sdk';

  // Initialize causal oracle
  const oracle = new CausalOracle({
    minConfidence: 0.95,
    requiredEvidence: ['telemetry', 'surveys', 'market_data']
  });

  // Verify causal claims
  const verification = await oracle.verifyHousehold({
    householdId: 'did:ixo:household/123',
    periodStart: '2024-01-01',
    periodEnd: '2024-01-31',
    evidence: {
      telemetry: deviceData,
      surveys: surveyData,
      marketData: marketPrices
    }
  });

  // Generate verification report
  if (verification.isValid) {
    const report = await verification.generateReport();
    console.log(`Causal Strength: ${report.causalStrength}`);
    console.log(`Confidence Level: ${report.confidence}`);
  }
  ```
</CodeGroup>